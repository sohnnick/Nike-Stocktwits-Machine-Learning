{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sohnnick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from dateutil.parser import parse\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Frame Databases and Obtain Metrics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NKE-explore.txt') as f:\n",
    "    nke_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json2df(json_data): \n",
    "    #create empty dictionary\n",
    "    dictdat = {'date':[], 'sentiment':[], 'body':[]}\n",
    "    #append to dictionary\n",
    "    for data in json_data:\n",
    "        if data['sentiment'] != None:\n",
    "            dictdat['sentiment'].append(data['sentiment']['class'])\n",
    "        else:\n",
    "            dictdat['sentiment'].append('None')\n",
    "        dictdat['date'].append(datetime.strptime(data['created_at'][:16], '%a, %d %b %Y'))\n",
    "        dictdat['body'].append(data['body'])\n",
    "    #convert to dataframe\n",
    "    df = pd.DataFrame(data=dictdat).sort_values(by='date').reset_index()\n",
    "    del df['index']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function\n",
    "text_nke = convert_json2df(nke_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>None</td>\n",
       "      <td>A lot of stocks now trading green:  $GS $WFC $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>None</td>\n",
       "      <td>Nike's EVP &amp; CFO just cashed-in 33,000 options...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>China dragged down a lot of giant companies la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>bullish</td>\n",
       "      <td>$NKE Buying the dip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>Drake Signs with Jordan Brand, Kanye with adid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE NIKE Redefines Basketball Footwear with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE gives you a chance to design shoes for Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>On http://stks.co/f00Qo ( http://stks.co/f00Qp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>On The Yield Game ( http://stks.co/dx9q ) Now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$JCP from my profit going to get some $NKE clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>\"@Stef540: $JCP from my profit going to get so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>Just a Glimpse of Competitive Analysis b/w $NK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$nke actually put on a position looks poised t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>In A Yoga Pants Glut, Whatâ€™s lululemon Worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE NIKE, Inc. Announces Second Quarter Fisca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>bullish</td>\n",
       "      <td>$NKE After Hours: 79.19 +0.24 (0.30%) Dec 5, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE will this time be different ?  http://stk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE $AAPL $DIS culture of perfection. better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE http://stks.co/pieF &amp;lt; interesting Wedg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>None</td>\n",
       "      <td>$NKE I think they are getting tired &amp; old on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date sentiment                                               body\n",
       "0  2013-12-03      None  A lot of stocks now trading green:  $GS $WFC $...\n",
       "1  2013-12-03      None  Nike's EVP & CFO just cashed-in 33,000 options...\n",
       "2  2013-12-04      None  China dragged down a lot of giant companies la...\n",
       "3  2013-12-04   bullish                               $NKE Buying the dip.\n",
       "4  2013-12-04      None  Drake Signs with Jordan Brand, Kanye with adid...\n",
       "5  2013-12-04      None  $NKE NIKE Redefines Basketball Footwear with t...\n",
       "6  2013-12-04      None  $NKE gives you a chance to design shoes for Ti...\n",
       "7  2013-12-05      None  On http://stks.co/f00Qo ( http://stks.co/f00Qp...\n",
       "8  2013-12-05      None  On The Yield Game ( http://stks.co/dx9q ) Now ...\n",
       "9  2013-12-05      None  $JCP from my profit going to get some $NKE clo...\n",
       "10 2013-12-05      None  \"@Stef540: $JCP from my profit going to get so...\n",
       "11 2013-12-05      None  Just a Glimpse of Competitive Analysis b/w $NK...\n",
       "12 2013-12-05      None  $nke actually put on a position looks poised t...\n",
       "13 2013-12-05      None  In A Yoga Pants Glut, Whatâ€™s lululemon Worth...\n",
       "14 2013-12-05      None  $NKE NIKE, Inc. Announces Second Quarter Fisca...\n",
       "15 2013-12-05   bullish  $NKE After Hours: 79.19 +0.24 (0.30%) Dec 5, 5...\n",
       "16 2013-12-06      None  $NKE will this time be different ?  http://stk...\n",
       "17 2013-12-06      None  $NKE $AAPL $DIS culture of perfection. better ...\n",
       "18 2013-12-07      None  $NKE http://stks.co/pieF &lt; interesting Wedg...\n",
       "19 2013-12-07      None  $NKE I think they are getting tired & old on t..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nke.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_metrics(df):\n",
    "    #obtain unique dates\n",
    "    date_list = list(set(list(df['date'])))\n",
    "    len(date_list)\n",
    "    date_list.sort()\n",
    "    \n",
    "    #group data\n",
    "    grouped_df = df.groupby('date')\n",
    "    \n",
    "    #obtain polarity, message volume, 1-day volume change, 10-day likelihood\n",
    "    polarity_list = []\n",
    "    volume_list = []\n",
    "    vchange1 = []\n",
    "    vchange10 = []\n",
    "    polarity_movaverage = []\n",
    "    for i in range(0, len(date_list)):\n",
    "        date_temp = grouped_df.get_group(date_list[i])\n",
    "        date_temp = list(date_temp['sentiment'])\n",
    "        polarity = (date_temp.count('bullish')-date_temp.count('bearish'))/len(date_temp)\n",
    "        polarity_list.append(polarity)\n",
    "        volume_list.append(len(date_temp))\n",
    "        if i == 0:\n",
    "            vchange1.append(None)\n",
    "        else:\n",
    "            day1change = (volume_list[i]-volume_list[i-1])/volume_list[i-1]\n",
    "            vchange1.append(day1change)\n",
    "        if i < 10:\n",
    "            vchange10.append(None)\n",
    "        else:\n",
    "            day10change = len(date_temp)/(sum(volume_list[i-10:i])/10)\n",
    "            vchange10.append(day10change)\n",
    "        if i >= 2:\n",
    "            movave = (polarity_list[i] + polarity_list[i-1] + polarity_list[i-2])/3\n",
    "            polarity_movaverage.append(movave)\n",
    "        else:\n",
    "            polarity_movaverage.append(None)\n",
    "    \n",
    "    #create a dataframe with the results\n",
    "    date_metrics_dict = {}\n",
    "    date_metrics_dict['date'] = date_list\n",
    "    date_metrics_dict['polarity'] = polarity_list\n",
    "    date_metrics_dict['st'] = polarity_movaverage\n",
    "    date_metrics_dict['msgvolume'] = volume_list\n",
    "    date_metrics_dict['mv1t'] = vchange1\n",
    "    date_metrics_dict['mv10t'] = vchange10\n",
    "    df_final = pd.DataFrame(data=date_metrics_dict)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function\n",
    "df_volume = obtain_metrics(text_nke)\n",
    "df_volume.head(20)\n",
    "df_volume.to_csv(\"df_volumemetrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_price = pd.read_csv('NKE-explore.csv')\n",
    "df_price = df_price.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_target(df_price):\n",
    "    length = len(df_price)\n",
    "    #only interested in the closing price\n",
    "    close = list(df_price['CLOSE'])\n",
    "    rt3 = []\n",
    "    rt5 = []\n",
    "    for i in range(0,length):\n",
    "        if i > length-4:\n",
    "            rt3.append(None)\n",
    "        else:\n",
    "            temp_3 = (close[i+3]-close[i])/close[i]\n",
    "            rt3.append(temp_3)\n",
    "        if i > length-6:\n",
    "            rt5.append(None)\n",
    "        else:\n",
    "            temp_5 = (close[i+5]-close[i])/close[i]\n",
    "            rt5.append(temp_5)\n",
    "    \n",
    "    prediction_dict = {}\n",
    "    prediction_dict['rt3'] = rt3\n",
    "    prediction_dict['rt5'] = rt5\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to obtain forward T day return\n",
    "df_prediction = prediction_target(df_price)\n",
    "df_prediction = pd.DataFrame(data=df_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>rt3</th>\n",
       "      <th>rt5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>30.810515</td>\n",
       "      <td>30.968887</td>\n",
       "      <td>30.676139</td>\n",
       "      <td>5472400</td>\n",
       "      <td>30.676139</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>0.009133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-27</td>\n",
       "      <td>30.359395</td>\n",
       "      <td>30.589756</td>\n",
       "      <td>30.133837</td>\n",
       "      <td>4870800</td>\n",
       "      <td>30.143435</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.040384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>30.100242</td>\n",
       "      <td>30.570559</td>\n",
       "      <td>30.066649</td>\n",
       "      <td>6044000</td>\n",
       "      <td>30.412186</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.035149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-08-29</td>\n",
       "      <td>30.330330</td>\n",
       "      <td>30.749243</td>\n",
       "      <td>30.277363</td>\n",
       "      <td>4600000</td>\n",
       "      <td>30.566269</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>0.023630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>30.677016</td>\n",
       "      <td>30.715537</td>\n",
       "      <td>30.142539</td>\n",
       "      <td>5851000</td>\n",
       "      <td>30.248472</td>\n",
       "      <td>0.040751</td>\n",
       "      <td>0.041070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>50.338380</td>\n",
       "      <td>50.627339</td>\n",
       "      <td>49.889998</td>\n",
       "      <td>8198400</td>\n",
       "      <td>49.889998</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>50.110001</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>50.060001</td>\n",
       "      <td>7610100</td>\n",
       "      <td>50.650002</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>50.259998</td>\n",
       "      <td>50.680000</td>\n",
       "      <td>50.110001</td>\n",
       "      <td>6730200</td>\n",
       "      <td>50.459999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>52.270000</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>11995300</td>\n",
       "      <td>51.849998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>50.830002</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>50.259998</td>\n",
       "      <td>12411900</td>\n",
       "      <td>50.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       OPEN       HIGH        LOW    VOLUME      CLOSE  \\\n",
       "0    2013-08-26  30.810515  30.968887  30.676139   5472400  30.676139   \n",
       "1    2013-08-27  30.359395  30.589756  30.133837   4870800  30.143435   \n",
       "2    2013-08-28  30.100242  30.570559  30.066649   6044000  30.412186   \n",
       "3    2013-08-29  30.330330  30.749243  30.277363   4600000  30.566269   \n",
       "4    2013-08-30  30.677016  30.715537  30.142539   5851000  30.248472   \n",
       "..          ...        ...        ...        ...       ...        ...   \n",
       "823  2016-11-30  50.338380  50.627339  49.889998   8198400  49.889998   \n",
       "824  2016-12-01  50.110001  51.250000  50.060001   7610100  50.650002   \n",
       "825  2016-12-02  50.259998  50.680000  50.110001   6730200  50.459999   \n",
       "826  2016-12-05  50.799999  52.270000  50.700001  11995300  51.849998   \n",
       "827  2016-12-06  50.830002  51.099998  50.259998  12411900  50.570000   \n",
       "\n",
       "          rt3       rt5  \n",
       "0   -0.003582  0.009133  \n",
       "1    0.003485  0.040384  \n",
       "2    0.017891  0.035149  \n",
       "3    0.025992  0.023630  \n",
       "4    0.040751  0.041070  \n",
       "..        ...       ...  \n",
       "823  0.039286       NaN  \n",
       "824 -0.001580       NaN  \n",
       "825       NaN       NaN  \n",
       "826       NaN       NaN  \n",
       "827       NaN       NaN  \n",
       "\n",
       "[828 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metricsandvalue = pd.concat([df_price, df_prediction], axis=1)\n",
    "df_metricsandvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricsandvalue.to_csv(\"df_stockmovement.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pre Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of characters/tickers to remove\n",
    "list_of_symbols = pd.read_csv('constituents_csv.csv')\n",
    "remove = list(list_of_symbols['Symbol'])\n",
    "temp = list('{}()[].,:;+-*/&|<>=~@#$?%!&*')\n",
    "#manually add some symbols/characters that should be removed\n",
    "remove1 = ['http', '\\'s', '``', '\\'\\'', '...', '--', '..', 'puc=yahoo', 'cm_ven=YAHOO',\n",
    "          'yptr=yahoo', '//dividendvaluebuilder.com/nike-nke-dividend-stock-analysis/',\n",
    "          'utm_medium=eps_update', '//marketrealist.com/', 'n\\'t', 'utm_source=stocktwits',\n",
    "          '//www.estimize.com/intro/nke', 'utm_content=NKE', 'chart=historical', '\\'',\n",
    "          '\\'m', 'utm_medium=reporting_this_week_consensus', '//simplywall.st/NYSE',\n",
    "          'utm_medium=stocktwits', '//link.scoutfin.com/8gyk/SHiJ2vhB2t', 'nke', 'Nike', 'I',\n",
    "          '//bit.ly/TTSNKE', 'chart=scatter-plot', 'past-future-earnings', 'anchor=past-future-earnings']\n",
    "remove = remove + temp + remove1\n",
    "#print(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_of_words(text):\n",
    "    body = list(text['body'])\n",
    "    wordlist = []\n",
    "    for i in range(0, len(body)):\n",
    "        text = body[i]\n",
    "        text_tokens = word_tokenize(text)\n",
    "        wordlist = wordlist + text_tokens\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = list_of_words(text_nke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565316"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to check if string is a date\n",
    "def is_date(string, fuzzy=False):\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary and filter the keys\n",
    "def word_dictionary(wordlist):\n",
    "    word_dict = {}\n",
    "    #get counts for each unique word word\n",
    "    for i in range(0, len(wordlist)):\n",
    "        if wordlist[i] in word_dict:\n",
    "            word_dict[wordlist[i]] = word_dict.get(wordlist[i])+1\n",
    "        else:\n",
    "            word_dict[wordlist[i]] = 1\n",
    "    print('total unique words:', len(word_dict.keys()))\n",
    "    \n",
    "    #filter the words\n",
    "    keys = list(word_dict.keys())\n",
    "    for i in keys:\n",
    "        #remove word if it appears less than 25 times\n",
    "        if word_dict.get(i) < 25:\n",
    "            del word_dict[i]\n",
    "        #remove word if it is a stopword\n",
    "        elif i in stopwords.words():\n",
    "            del word_dict[i]\n",
    "        #remove word if it falls under the words to remove listed above\n",
    "        elif i in remove:\n",
    "            del word_dict[i]\n",
    "        elif is_date(i) == True:\n",
    "            del word_dict[i]\n",
    "        elif i.isnumeric() == True:\n",
    "            del word_dict[i]\n",
    "    print('total unique words after filtering:', len(word_dict))\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique words: 37828\n",
      "total unique words after filtering: 1482\n"
     ]
    }
   ],
   "source": [
    "word_dict = word_dictionary(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which words occur most frequently and discover any data that needs to be filtered\n",
    "#sorted(word_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(word_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter dataframe such that the posts in a given day form one document and then determine tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A lot of stocks now trading green:  $GS $WFC $JPM $PG $KO $TRV $VZ $XOM $CVX $NKE $PM $CLX $MCD'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_nke['body'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(wordlist, word_features):\n",
    "    data = {}\n",
    "    #laplace smoothing numerator\n",
    "    data = data.fromkeys(word_features,0)\n",
    "    for feature in word_features:\n",
    "        for word in wordlist:\n",
    "            if feature == word:\n",
    "                data[feature] = data.get(feature) + 1\n",
    "    #for key in data:\n",
    "        #laplace smoothing denominator\n",
    "        #data[key] = data.get(key)/(len(wordlist)+2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tf_dataframe(text, word_features):    \n",
    "    dates = list(set(list(text['date'])))\n",
    "    dates.sort()\n",
    "    text_dictbydate = []\n",
    "    for i in range(0, len(dates)):\n",
    "        temp = text[text['date'] == dates[i]]['body']\n",
    "        b = []\n",
    "        for string in temp:\n",
    "            a = word_tokenize(string)\n",
    "            b = b + a\n",
    "        text_dictbydate.append(tf(b, word_features))\n",
    "    df_tf = pd.DataFrame(data=text_dictbydate)\n",
    "    #df_tf['date'] = dates\n",
    "    date_df = pd.DataFrame({'date': dates})\n",
    "    df_tf = pd.concat([date_df, df_tf], axis=1)\n",
    "    return df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lot</th>\n",
       "      <th>stocks</th>\n",
       "      <th>trading</th>\n",
       "      <th>green</th>\n",
       "      <th>EVP</th>\n",
       "      <th>CFO</th>\n",
       "      <th>cashed-in</th>\n",
       "      <th>options</th>\n",
       "      <th>China</th>\n",
       "      <th>...</th>\n",
       "      <th>Brean</th>\n",
       "      <th>DWTI</th>\n",
       "      <th>lights</th>\n",
       "      <th>7x</th>\n",
       "      <th>5x</th>\n",
       "      <th>E2</th>\n",
       "      <th>https</th>\n",
       "      <th>NKE/</th>\n",
       "      <th>ApparelAndAccessories</th>\n",
       "      <th>0.51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>2016-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1081</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082 rows × 1483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  lot  stocks  trading  green  EVP  CFO  cashed-in  options  \\\n",
       "0    2013-12-03    1       1        1      1    1    1          1        1   \n",
       "1    2013-12-04    1       0        0      0    0    0          0        0   \n",
       "2    2013-12-05    0       0        0      0    0    0          0        0   \n",
       "3    2013-12-06    0       0        0      0    0    0          0        0   \n",
       "4    2013-12-07    0       0        0      0    0    0          0        0   \n",
       "...         ...  ...     ...      ...    ...  ...  ...        ...      ...   \n",
       "1077 2016-12-01    0       0        0      0    0    0          0        0   \n",
       "1078 2016-12-02    0       1        0      1    0    0          0        1   \n",
       "1079 2016-12-03    0       0        0      0    0    0          0        0   \n",
       "1080 2016-12-04    0       1        0      0    0    0          0        1   \n",
       "1081 2016-12-05    1       3        1      2    0    0          0        0   \n",
       "\n",
       "      China  ...  Brean  DWTI  lights  7x  5x  E2  https  NKE/  \\\n",
       "0         0  ...      0     0       0   0   0   0      0     0   \n",
       "1         1  ...      0     0       0   0   0   0      0     0   \n",
       "2         0  ...      0     0       0   0   0   0      0     0   \n",
       "3         0  ...      0     0       0   0   0   0      0     0   \n",
       "4         0  ...      0     0       0   0   0   0      0     0   \n",
       "...     ...  ...    ...   ...     ...  ..  ..  ..    ...   ...   \n",
       "1077      0  ...      0     0       1   0   0   0      2     0   \n",
       "1078      0  ...      0     0       0   0   0   0      3     0   \n",
       "1079      0  ...      0     0       0   0   0   0      1     0   \n",
       "1080      0  ...      0     0       0   0   0   0      0     0   \n",
       "1081      0  ...      0     0       0   0   3   0     12     0   \n",
       "\n",
       "      ApparelAndAccessories  0.51  \n",
       "0                         0     0  \n",
       "1                         0     0  \n",
       "2                         0     0  \n",
       "3                         0     0  \n",
       "4                         0     0  \n",
       "...                     ...   ...  \n",
       "1077                      0     0  \n",
       "1078                      0     0  \n",
       "1079                      0     0  \n",
       "1080                      0     0  \n",
       "1081                      1     0  \n",
       "\n",
       "[1082 rows x 1483 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf = get_tf_dataframe(text_nke, word_features)\n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(text, word_features):    \n",
    "    dates = list(set(list(text['date'])))\n",
    "    dates.sort()\n",
    "    \n",
    "    idf = {}\n",
    "    idf = idf.fromkeys(word_features, 1)\n",
    "    \n",
    "    for i in range(0, len(dates)):\n",
    "        temp = text[text['date'] == dates[i]]['body']\n",
    "        b = []\n",
    "        for string in temp:\n",
    "            a = word_tokenize(string)\n",
    "            b = b + a\n",
    "        for word in word_features:\n",
    "            if word in b:\n",
    "                idf[word] = idf.get(word)+1\n",
    "    for key in idf:\n",
    "        idf[key] = np.log(len(dates)/idf.get(key))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#obtain idf values for features\n",
    "dict_idf = get_idf(text_nke, word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.062310661991895"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this value makes sense as we can see that the word earnings appears most frequently (not in terms of number of docs)\n",
    "#but in terms of absolute frequency\n",
    "#from this, a low log(Corpus volume/number of docs where earnings occurs) should be relatively low\n",
    "dict_idf['earnings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date  a  b  c\n",
      "0  1000  3 -1  5\n",
      "1  2000 -1  1  4\n"
     ]
    }
   ],
   "source": [
    "#test out something\n",
    "temp = [{'a': 3, 'b': -1, 'c': 5}, {'a': -1, 'b': 1, 'c': 4}]\n",
    "dates = {'date': [1000, 2000]}\n",
    "dates = pd.DataFrame(dates)\n",
    "frog = pd.DataFrame(temp)\n",
    "df_temp = pd.concat([dates, frog], axis=1)\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(df_tf, dict_idf):\n",
    "    tfidf = df_tf\n",
    "    for key in dict_idf:\n",
    "        tfidf[key] = tfidf[key].apply(lambda x: x*dict_idf.get(key))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#obtain the final TFIDF dataframe\n",
    "df_tfidf = get_tfidf(df_tf, dict_idf)\n",
    "df_tfidf.head(5)\n",
    "df_tfidf.to_csv(\"df_tfidf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
